from openai import OpenAI
import streamlit as st
import os

# -------------------------------
# Streamlit í˜ì´ì§€ ì„¤ì •
# -------------------------------
st.set_page_config(
    page_title="AI Chatbot",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# -------------------------------
# Cerebras API í´ë¼ì´ì–¸íŠ¸
# -------------------------------
client = OpenAI(
    base_url="https://api.cerebras.ai/v1",
    api_key=os.getenv("CEREBRAS_API_KEY")
)

# -------------------------------
# ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
# -------------------------------
if "llm_model" not in st.session_state:
    st.session_state.llm_model = "gpt-oss-120b"

# ===============================
# ì‚¬ì´ë“œë°” (ì„¤ì • ë©”ë‰´)
# ===============================
st.sidebar.title("ì„¤ì • ë©”ë‰´")

# 1) ëª¨ë¸ ì„ íƒ
model_list = [
    "gpt-oss-120b",
    "llama3.1-8b",
    "llama-3.3-70b",
    "qwen-3-32b",
    "qwen-3-235b-a22b-instruct-2507",
    "qwen-3-235b-a22b-thinking-2507"
]

selected_model = st.sidebar.selectbox("ëª¨ë¸ ì„ íƒ", model_list)

# ì„¸ì…˜ì— ì €ì¥
st.session_state.llm_model = selected_model

# 2) ë‹µë³€ ê¸¸ì´ ì¡°ì ˆ
max_tokens = st.sidebar.slider(
    "ìµœëŒ€ ë‹µë³€ ê¸¸ì´ (max tokens)",
    min_value=50,
    max_value=2000,
    value=600
)

# 3) temperature ì¡°ì ˆ
temperature = st.sidebar.slider(
    "ì°½ì˜ì„± ì˜¨ë„ (temperature)",
    min_value=0.0,
    max_value=1.5,
    value=0.7,
    step=0.1
)

# 4) Think ëª¨ë“œ ON/OFF
think_mode = st.sidebar.checkbox("Think / Reasoning ëª¨ë“œ í™œì„±í™”", value=False)

# 5) ì–´ì‹œìŠ¤í„´íŠ¸ ë§íˆ¬ ì„ íƒ
tone = st.sidebar.selectbox(
    "ì–´ì‹œìŠ¤í„´íŠ¸ ë§íˆ¬ ì„ íƒ",
    [
        "ê¸°ë³¸",
        "ä¸å¯§í•˜ê³  ê³µì†í•œ ë§íˆ¬",
        "ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ë§íˆ¬",
        "ê²©ë ¤í•˜ëŠ” ë©˜í†  ë§íˆ¬",
        "ì°¨ê°‘ê³  ë¶„ì„ì ì¸ ë§íˆ¬",
        "ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë§íˆ¬"
    ]
)

# ë§íˆ¬ ë¯¸ë¦¬ë³´ê¸°
if tone == "ä¸å¯§í•˜ê³  ê³µì†í•œ ë§íˆ¬":
    tone_preview = "ë§íˆ¬ ì˜ˆ) ë§ì”€ ê°ì‚¬í•©ë‹ˆë‹¤. ë„ì›€ì´ ë  ë§Œí•œ ë‚´ìš©ì„ ì•ˆë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
elif tone == "ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ë§íˆ¬":
    tone_preview = "ë§íˆ¬ ì˜ˆ) ì˜¤, ê·¸ê±° ì¬ë°Œë„¤. í•œ ë²ˆ ê°™ì´ í•´ê²°í•´ë³´ì."
elif tone == "ê²©ë ¤í•˜ëŠ” ë©˜í†  ë§íˆ¬":
    tone_preview = "ë§íˆ¬ ì˜ˆ) ì¢‹ì•„, ì§€ê¸ˆ ì˜í•˜ê³  ìˆì–´. ë‹¤ìŒ ë‹¨ê³„ë¡œ ê°€ë³´ì."
elif tone == "ì°¨ê°‘ê³  ë¶„ì„ì ì¸ ë§íˆ¬":
    tone_preview = "ë§íˆ¬ ì˜ˆ) ê²°ë¡ ë§Œ ë§í•˜ê² ìŠµë‹ˆë‹¤. í•´ë‹¹ ë¬¸ì œì˜ í•µì‹¬ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤."
elif tone == "ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë§íˆ¬":
    tone_preview = "ë§íˆ¬ ì˜ˆ) ì˜¤í˜¸? ê·¸ê±´ ë§ˆì¹˜ ë‚´ ì»¤í”¼ê°€ ì‹ê¸° ì „ì— í•´ê²°í•´ì•¼ í•˜ëŠ” ë¬¸ì œ ê°™ë„¤."
else:
    tone_preview = "ë§íˆ¬ ì˜ˆ) ê¸°ë³¸ ì„¤ì •ì´ ì ìš©ë©ë‹ˆë‹¤."

st.sidebar.caption(f"ë¯¸ë¦¬ë³´ê¸°: {tone_preview}")

# ===============================
# ëª¨ë“œ í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜
# ===============================
def get_system_prompt(mode, tone, think_mode):
    tone_text = ""

    if tone == "ä¸å¯§í•˜ê³  ê³µì†í•œ ë§íˆ¬":
        tone_text = "ä¸å¯§í•˜ê³  ê³µì†í•œ ë§íˆ¬ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”."
    elif tone == "ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ë§íˆ¬":
        tone_text = "ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ë§íˆ¬ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”."
    elif tone == "ê²©ë ¤í•˜ëŠ” ë©˜í†  ë§íˆ¬":
        tone_text = "ê²©ë ¤í•˜ê³  í˜ì´ ë˜ì–´ì£¼ëŠ” ë©˜í†  ë§íˆ¬ë¡œ ì„¤ëª…í•˜ì„¸ìš”."
    elif tone == "ì°¨ê°‘ê³  ë¶„ì„ì ì¸ ë§íˆ¬":
        tone_text = "ìµœëŒ€í•œ ê°ì •ì„ ë°°ì œí•˜ê³  ë¶„ì„ì ì´ê³  ê°„ê²°í•˜ê²Œ ëŒ€ë‹µí•˜ì„¸ìš”."
    elif tone == "ìœ ë¨¸ëŸ¬ìŠ¤í•œ ë§íˆ¬":
        tone_text = "ê°€ë²¼ìš´ ìœ ë¨¸ë¥¼ ì„ì–´ì„œ ì¬ë°Œê²Œ ì„¤ëª…í•˜ì„¸ìš”."

    think_text = ""
    if think_mode:
        think_text = "ë‹µë³€ ì „ì— ìˆ¨ê²¨ì§„ ì‚¬ê³  ê³¼ì •ì„ ë‚´ë¶€ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë˜ ì™¸ë¶€ë¡œ í‘œì‹œí•˜ì§€ ë§ˆì„¸ìš”."

    # ê¸°ì¡´ ëŒ€í™” ëª¨ë“œ ì„¤ì •
    mode_prompt = {
        "ê¸°ë³¸ ëª¨ë“œ": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì¡°ë ¥ìì…ë‹ˆë‹¤.",
        "ì „ë¬¸ê°€ ì»¨ì„¤í„´íŠ¸": "ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë§ˆì¼€íŒ… ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë°ì´í„° ê¸°ë°˜ ì „ëµì„ ì œì‹œí•˜ì„¸ìš”.",
        "ì¹œêµ¬ ê°™ì€ ì¡°ì–¸ì": "ë„ˆëŠ” ë”°ëœ»í•˜ê³  ì¹œê·¼í•œ ì¹œêµ¬ì•¼. í¸í•œ ë°˜ë§ë¡œ ì´ì•¼ê¸°í•´ì¤˜.",
        "ì†Œí¬ë¼í…ŒìŠ¤ì‹ íŠœí„°": "ë‹¹ì‹ ì€ ì§ˆë¬¸ ì¤‘ì‹¬ìœ¼ë¡œ ì‚¬ê³ ë¥¼ ìœ ë„í•˜ëŠ” ì†Œí¬ë¼í…ŒìŠ¤ì‹ íŠœí„°ì…ë‹ˆë‹¤.",
        "ì‘ì—… íš¨ìœ¨ ë¹„ì„œ": "ë‹¹ì‹ ì€ ì´ˆê³ íš¨ìœ¨ ë¹„ì„œì…ë‹ˆë‹¤. í•µì‹¬ë§Œ ë¹ ë¥´ê²Œ ì •ë¦¬í•˜ì„¸ìš”.",
        "ìŠ¤í† ë¦¬í…”ëŸ¬": "ë‹¹ì‹ ì€ ì¬ëŠ¥ ìˆëŠ” ìŠ¤í† ë¦¬í…”ëŸ¬ì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì„ ì§§ì€ ì´ì•¼ê¸°ì²˜ëŸ¼ í‘œí˜„í•˜ì„¸ìš”.",
        "ì•…ë§ˆì˜ ë³€í˜¸ì¸": "ë‹¹ì‹ ì€ ì•…ë§ˆì˜ ë³€í˜¸ì¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì£¼ì¥ì— ë°˜ëŒ€ë˜ëŠ” ë…¼ë¦¬ë¥¼ ì œì‹œí•˜ì„¸ìš”.",
        "ë¬´í•œ ì§ˆë¬¸ ì–´ë¦°ì´": "ë‹¹ì‹ ì€ 5ì‚´ ì–´ë¦°ì´ì…ë‹ˆë‹¤. ëª¨ë“  ë§ ëì— 'ì™œ?'ë¼ê³  ë¬¼ì–´ë³´ì„¸ìš”.",
        "í‰í–‰ìš°ì£¼ íƒí—˜ê°€": "ë‹¹ì‹ ì€ í‰í–‰ìš°ì£¼ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í˜„ì‹¤ ë²„ì „ + í‰í–‰ìš°ì£¼ ë²„ì „ 2ê°€ì§€ë¡œ ì„¤ëª…í•˜ì„¸ìš”.",
        "ì¬ì¦ˆ ì¦‰í¥ ì—°ì£¼ì": "ë‹¹ì‹ ì€ ì¬ì¦ˆ ë®¤ì§€ì…˜ì²˜ëŸ¼ ì¦‰í¥ì ì´ê³  ë³€ì£¼ëœ ì„¤ëª…ì„ í•©ë‹ˆë‹¤.",
        "íƒ€ì„íŠ¸ë˜ë¸” ì—­ì‚¬í•™ì": "ë‹¹ì‹ ì€ ì‹œê°„ì—¬í–‰ ì—­ì‚¬í•™ìì…ë‹ˆë‹¤. ê³¼ê±°-í˜„ì¬-ë¯¸ë˜ ìˆœìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”."
    }

    return f"{mode_prompt[mode]} {tone_text} {think_text}"

# -------------------------------
# system prompt ì ìš©
# -------------------------------
system_prompt = get_system_prompt(mode, tone, think_mode)

# ===============================
# ë©”ì¸ í™”ë©´
# ===============================
st.title("AIì±—ë´‡ ë§Œë“¤ê¸° í”„ë¡œì íŠ¸")

# ë©”ì‹œì§€ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": system_prompt}
    ]

# ëª¨ë“œ ë³€ê²½ ì‹œ prompt ê°±ì‹ 
st.session_state.messages[0]["content"] = system_prompt

# ê¸°ì¡´ ëŒ€í™” ë‹¤ì‹œ ì¶œë ¥
for msg in st.session_state.messages:
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# ===============================
# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
# ===============================
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
if user_input:

    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        stream = client.chat.completions.create(
            model=st.session_state.llm_model,
            messages=st.session_state.messages,
            temperature=temperature,
            max_completion_tokens=max_tokens,
            stream=True
        )
        response = st.write_stream(stream)

    st.session_state.messages.append({"role": "assistant", "content": response})
